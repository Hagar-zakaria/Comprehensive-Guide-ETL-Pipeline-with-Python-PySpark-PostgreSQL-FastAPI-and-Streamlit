In this project, we will create an ETL (Extract, Transform, Load) pipeline to process COVID-19 data using the technologies mentioned in the job description:

- Python (with Pandas, NumPy)
- PySpark
- SQL (PostgreSQL)
- FastAPI
- Streamlit
- Docker
- Azure Data Platform (Optional)
- Data Warehousing


Project Steps
1. Setting Up the Environment
Install Required Libraries:

First, we'll install the necessary libraries using pip by using bash;
![image](https://github.com/Hagar-zakaria/Comprehensive-Guide-ETL-Pipeline-with-Python-PySpark-PostgreSQL-FastAPI-and-Streamlit/assets/93611934/703045a0-acc5-4f62-88d0-98ba369b27ba)

Run PostgreSQL Using Docker:

We'll run PostgreSQL using Docker to have a consistent environment:
![image](https://github.com/Hagar-zakaria/Comprehensive-Guide-ETL-Pipeline-with-Python-PySpark-PostgreSQL-FastAPI-and-Streamlit/assets/93611934/c96b694e-de5d-458d-a45e-17971ee272b0)
